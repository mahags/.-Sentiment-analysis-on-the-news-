{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4768618e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: newsapi in c:\\users\\admin\\anaconda3\\lib\\site-packages (0.1.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: requests in c:\\users\\admin\\anaconda3\\lib\\site-packages (from newsapi) (2.28.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests->newsapi) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests->newsapi) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests->newsapi) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests->newsapi) (3.4)\n"
     ]
    }
   ],
   "source": [
    "pip install newsapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e6f7058",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    " \n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "990fea2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50f9d12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the stock symbol (e.g., AAPL): aapl\n",
      "Error: Failed to retrieve news from https://finance.yahoo.com/quote/aapl/news (404 Client Error: Not Found for url: https://finance.yahoo.com/quote/aapl/news)\n",
      "No news articles found for aapl on Yahoo Finance.\n"
     ]
    }
   ],
   "source": [
    "def analyze_news_sentiment(stock_symbol, base_url=\"https://finance.yahoo.com/quote/\"):\n",
    "  \"\"\"\n",
    "  Attempts to analyze sentiment of news related to the stock symbol\n",
    "  by scraping a finance website (use with caution due to scraping limitations).\n",
    "\n",
    "  Args:\n",
    "      stock_symbol: The stock ticker symbol (e.g., \"AAPL\").\n",
    "      base_url: The base URL of the finance website (default: Yahoo Finance).\n",
    "\n",
    "  Returns:\n",
    "      A list of tuples containing the scraped headline (if found)\n",
    "      and its sentiment analysis (positive, neutral, negative).\n",
    "  \"\"\"\n",
    "  url = f\"{base_url}{stock_symbol}/news\"\n",
    "  try:\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  # Raise an exception for failed requests\n",
    "  except requests.exceptions.RequestException as e:\n",
    "    print(f\"Error: Failed to retrieve news from {url} ({e})\")\n",
    "    return []\n",
    "\n",
    "  soup = BeautifulSoup(response.content, 'html.parser')\n",
    "  news_items = soup.find_all('li', class_=\"news-item\")  # Adjust selectors based on website structure\n",
    "  sentiments = []\n",
    "  analyzer = SentimentIntensityAnalyzer()\n",
    "  for item in news_items:\n",
    "    headline = item.find('a', class_=\"news-item__ headline\")  # Adjust selectors for headline elements\n",
    "    if headline:\n",
    "      headline_text = headline.text.strip()\n",
    "      scores = analyzer.polarity_scores(headline_text)\n",
    "      compound_score = scores[\"compound\"]\n",
    "      sentiment = determine_sentiment(compound_score)\n",
    "      sentiments.append((headline_text, sentiment))\n",
    "  return sentiments\n",
    "\n",
    "def determine_sentiment(compound_score):\n",
    "  \"\"\"\n",
    "  Determines sentiment based on the compound score from VADER.\n",
    "\n",
    "  Args:\n",
    "      compound_score: The compound sentiment score from VADER analysis.\n",
    "\n",
    "  Returns:\n",
    "      A string representing the sentiment (positive, neutral, negative).\n",
    "  \"\"\"\n",
    "  if compound_score >= 0.05:\n",
    "    return \"Positive\"\n",
    "  elif compound_score <= -0.05:\n",
    "    return \"Negative\"\n",
    "  else:\n",
    "    return \"Neutral\"\n",
    "\n",
    "def main():\n",
    "  \"\"\"\n",
    "  Main function to perform sentiment analysis on scraped news (use with caution).\n",
    "  \"\"\"\n",
    "  stock_symbol = input(\"Enter the stock symbol (e.g., AAPL): \")\n",
    "  sentiments = analyze_news_sentiment(stock_symbol)\n",
    "\n",
    "  if sentiments:\n",
    "    print(f\"Sentiment Analysis for News related to {stock_symbol} (scraped from Yahoo Finance)\")\n",
    "    for headline, sentiment in sentiments:\n",
    "      print(f\"- '{headline}': {sentiment}\")\n",
    "  else:\n",
    "    print(f\"No news articles found for {stock_symbol} on Yahoo Finance.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
